{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrad as tg\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.verifier import TextualVerifierWithTracker\n",
    "from textgrad.loss import TextLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eugeniusms/Development/SKRIPSI/sevet/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "engine = get_engine(\"gemini-1.5-pro\")\n",
    "tg.set_backward_engine(\"gemini-1.5-pro\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution = \"\"\"To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\n",
    "x = (-b ± √(b^2 - 4ac)) / 2a\n",
    "a = 3, b = -7, c = 2\n",
    "x = (7 ± √((-7)^2 + 4(3)(2))) / 6\n",
    "x = (7 ± √73) / 6\n",
    "The solutions are:\n",
    "x1 = (7 + √73)\n",
    "x2 = (7 - √73)\"\"\"\n",
    "\n",
    "solution = Variable(initial_solution,\n",
    "                       requires_grad=True,\n",
    "                       role_description=\"solution to the math question\")\n",
    "\n",
    "loss_system_prompt = Variable(\"\"\"You will evaluate a solution to a math question. \n",
    "Do not attempt to solve it yourself, do not give a solution, only identify errors. Be super concise.\"\"\",\n",
    "                              requires_grad=False,\n",
    "                              role_description=\"system prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = TextualGradientDescent([solution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL LOSS: The calculation of  b² - 4ac was incorrect: it should be (-7)² - 4 * 3 * 2 = 49 - 24 = 25, not 49 + 24 = 73.  Also, the division by 6 is missing in the final answers for x1 and x2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = TextLoss(loss_system_prompt, engine=engine)\n",
    "loss_value = loss(solution) # Forward method in Loss Function\n",
    "\n",
    "print(\"INITIAL LOSS:\", loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:textgrad:TextualVerifier: Start verification process...\n",
      "INFO:textgrad:TextualVerifier: Ready to verify 1 calculation steps...\n",
      "INFO:textgrad:TextualVerifier: Verifying step 1/1...\n",
      "INFO:textgrad:TextualVerifier: Generating step 1 variant 1/1...\n",
      "INFO:textgrad:TextualVerifier: Running majority voting for step 1...\n",
      "VERIFIED RESULT: <VERIFIED>The calculation correctly identifies both errors in the provided solution.  The discriminant is calculated incorrectly (it should be 25, not 73) and the division by 6 is missing from the final answers.\n",
      "</VERIFIED>\n"
     ]
    }
   ],
   "source": [
    "loss_verification_task_prompts = [\n",
    "    \"\"\"\n",
    "    1. When using $instruction to $instance, I got the loss $calculation.\n",
    "    2. Evaluate the loss $calculation value correctly reflects the performance of the instance.\n",
    "    3. If the loss $calculation is incorrect or inconsistent, provide the corrected version of the loss $calculation. \n",
    "    4. Do NOT calculate the solution/instance, evaluate $calculation ONLY.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "loss_verifier = TextualVerifierWithTracker(\n",
    "    verifier_engine=engine, \n",
    "    use_cot_generation=False,\n",
    "    use_step_breakdown=False,\n",
    "    verification_task_prompts=loss_verification_task_prompts,\n",
    "    enable_logging=True\n",
    ")\n",
    "\n",
    "loss_verified_result = loss_verifier.verify(instance=solution,\n",
    "                                  instruction=loss_system_prompt,\n",
    "                                  calculation=loss_value)\n",
    "\n",
    "print(\"VERIFIED RESULT:\", loss_verified_result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value.set_value(loss_verified_result.value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here is a conversation:\\n\\n<CONVERSATION><LM_SYSTEM_PROMPT> You will evaluate a solution to a math question. \\nDo not attempt to solve it yourself, do not give a solution, only identify errors. Be super concise. </LM_SYSTEM_PROMPT>\\n\\n<LM_INPUT> To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\\nx = (-b ± √(b^2 - 4ac)) / 2a\\na = 3, b = -7, c = 2\\nx = (7 ± √((-7)^2 + 4(3)(2))) / 6\\nx = (7 ± √73) / 6\\nThe solutions are:\\nx1 = (7 + √73)\\nx2 = (7 - √73) </LM_INPUT>\\n\\n<LM_OUTPUT> <VERIFIED>The calculation correctly identifies both errors in the provided solution.  The discriminant is calculated incorrectly (it should be 25, not 73) and the division by 6 is missing from the final answers.\\n</VERIFIED> </LM_OUTPUT>\\n\\n</CONVERSATION>\\n\\nThis conversation is potentially part of a larger system. The output is used as response from the language model\\n\\nHere is the feedback we got for solution to the math question in the conversation:\\n\\n<FEEDBACK>The language model evaluation identified two distinct errors in the solution:\\n\\n1. **Incorrect Discriminant Calculation:** The discriminant (the part inside the square root, b² - 4ac) was calculated as 73.  The feedback here should be to double-check the arithmetic, specifically the signs and multiplication involved in calculating (-7)² - 4 * 3 * 2.  The correct calculation should yield 49 - 24 = 25.  Emphasize the importance of careful calculation and suggest breaking down the calculation into smaller steps to avoid errors.\\n\\n2. **Missing Division:** The final solutions are missing the division by 2*a (which is 6 in this case). The feedback should point out that the entire numerator (7 ± √(discriminant)) needs to be divided by 6.  The solutions should be expressed as fractions with 6 as the denominator.  Suggest explicitly writing the division step to avoid omitting it.\\n</FEEDBACK>\\n\\n']\n",
      "Optimized Solution: To solve the equation 3x^2 - 7x + 2 = 0, we use the quadratic formula:\n",
      "x = (-b ± √(b^2 - 4ac)) / 2a\n",
      "Where a = 3, b = -7, and c = 2.\n",
      "\n",
      "So, x = (7 ± √((-7)^2 - 4 * 3 * 2)) / (2 * 3)\n",
      "x = (7 ± √(49 - 24)) / 6\n",
      "x = (7 ± √25) / 6\n",
      "x = (7 ± 5) / 6\n",
      "\n",
      "Therefore, the solutions are:\n",
      "x1 = (7 + 5) / 6 = 12/6 = 2\n",
      "x2 = (7 - 5) / 6 = 2/6 = 1/3\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "loss_value.backward()\n",
    "\n",
    "optimizer.step()\n",
    "print(\"Optimized Solution:\", solution.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextualGradientDescent' object has no attribute 'verifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     25\u001b[39m instance = Variable(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minitial_solution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_solution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mloss_value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m                     requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     27\u001b[39m                     role_description=\u001b[33m\"\u001b[39m\u001b[33minstance\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m optimizer_instruction = Variable(\u001b[33m\"\"\"\u001b[39m\u001b[33mYou will optimize $initial_solution based on $loss_value. Be super concise.\u001b[39m\u001b[33m\"\"\"\u001b[39m,\n\u001b[32m     30\u001b[39m                                 requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     31\u001b[39m                                 role_description=\u001b[33m\"\u001b[39m\u001b[33moptimizer prompt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m verified_result = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverifier\u001b[49m.verify(instance=instance,\n\u001b[32m     34\u001b[39m                                   instruction=optimizer_instruction,\n\u001b[32m     35\u001b[39m                                   calculation=solution)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVERIFIED RESULT:\u001b[39m\u001b[33m\"\u001b[39m, verified_result.value)\n",
      "\u001b[31mAttributeError\u001b[39m: 'TextualGradientDescent' object has no attribute 'verifier'"
     ]
    }
   ],
   "source": [
    "optimizer_verification_task_prompts = [\n",
    "    # Perspective 1: Rule-based verifier (objective, procedural)\n",
    "    \"\"\"\n",
    "    Evaluate the calculation step strictly based on mathematical correctness and procedural rules. \n",
    "    If the step violates any algebraic or logical principle, replace it with the corrected version of that step only. \n",
    "    Do not proceed to solve the full problem.\n",
    "    \"\"\",\n",
    "\n",
    "    # Perspective 2: Teaching assistant (didactic, pedagogical)\n",
    "    \"\"\"\n",
    "    Review the calculation step from the perspective of a teaching assistant helping a student learn. \n",
    "    If there's an error or suboptimal explanation, provide a corrected version that would best aid the student's understanding. \n",
    "    Focus only on the step in question, without solving the full problem.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "optimizer_verifier = TextualVerifierWithTracker(\n",
    "    verifier_engine=engine, \n",
    "    use_cot_generation=True,\n",
    "    use_step_breakdown=True,\n",
    "    verification_task_prompts=optimizer_verification_task_prompts,\n",
    "    enable_logging=True\n",
    ")\n",
    "\n",
    "instance = Variable(f\"initial_solution: {initial_solution}\\nloss_value: {loss_value}\",\n",
    "                    requires_grad=False,\n",
    "                    role_description=\"instance\")\n",
    "\n",
    "optimizer_instruction = Variable(\"\"\"You will optimize $initial_solution based on $loss_value. Be super concise.\"\"\",\n",
    "                                requires_grad=False,\n",
    "                                role_description=\"optimizer prompt\")\n",
    "\n",
    "verified_result = optimizer_verifier.verify(instance=instance,\n",
    "                                  instruction=optimizer_instruction,\n",
    "                                  calculation=solution)\n",
    "\n",
    "print(\"VERIFIED RESULT:\", verified_result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "loss_tracker_data = loss_verifier.get_tracker()\n",
    "optimizer_tracker_data = optimizer_verifier.get_tracker()\n",
    "\n",
    "tracker_data = {\n",
    "    \"loss_tracker\": loss_tracker_data,\n",
    "    \"optimizer_tracker\": optimizer_tracker_data,\n",
    "}\n",
    "\n",
    "with open('tracker_results/loss_optimizer_verification.json', 'w') as f:\n",
    "    json.dump(tracker_data, f, indent=4, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "860e0dc2175a55dd9a80ac360791d93c13f4935a3c9aca3a9a76262c7d69eace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
