{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Experiment Evaluaton TV2 TextGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textgrad as tg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "# TextGrad\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.verifier import TextualVerifierV2Analysis\n",
    "from textgrad.loss import TextLoss\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loading Function\n",
    "def load_prm800k_safely():\n",
    "    \"\"\"Load PRM800K with error handling\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Attempting to load PRM800K dataset...\")\n",
    "        \n",
    "        # Loading with streaming first (safer for large datasets)\n",
    "        dataset = load_dataset(\"tasksource/PRM800K\", streaming=True)\n",
    "        print(\"[V] Successfully loaded PRM800K in streaming mode\")\n",
    "        return dataset, \"streaming\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[X] Streaming failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load PRM800K dataset...\n",
      "[V] Successfully loaded PRM800K in streaming mode\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_stream, load_method = load_prm800k_safely()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDatasetDict({\n",
       "    train: IterableDataset({\n",
       "        features: Unknown,\n",
       "        num_shards: 2\n",
       "    })\n",
       "    test: IterableDataset({\n",
       "        features: Unknown,\n",
       "        num_shards: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labeler</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>generation</th>\n",
       "      <th>is_quality_control_question</th>\n",
       "      <th>is_initial_screening_question</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e90a38f3-3135-4465-87af-3e6322e3d772</td>\n",
       "      <td>2022-07-13T18:55:54.496450</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'problem': 'How many seconds are in 7.8 minut...</td>\n",
       "      <td>{'steps': [{'completions': [{'text': '7.8 minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e90a38f3-3135-4465-87af-3e6322e3d772</td>\n",
       "      <td>2022-07-17T16:56:51.323252</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'problem': 'How many positive two-digit integ...</td>\n",
       "      <td>{'steps': [{'completions': [{'text': \"Let's ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e90a38f3-3135-4465-87af-3e6322e3d772</td>\n",
       "      <td>2022-07-02T18:33:27.255302</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'problem': 'The fifth and eighth terms of a g...</td>\n",
       "      <td>{'steps': [{'completions': [{'text': 'So we ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                labeler                   timestamp  \\\n",
       "0  e90a38f3-3135-4465-87af-3e6322e3d772  2022-07-13T18:55:54.496450   \n",
       "1  e90a38f3-3135-4465-87af-3e6322e3d772  2022-07-17T16:56:51.323252   \n",
       "2  e90a38f3-3135-4465-87af-3e6322e3d772  2022-07-02T18:33:27.255302   \n",
       "\n",
       "  generation  is_quality_control_question  is_initial_screening_question  \\\n",
       "0       None                        False                          False   \n",
       "1       None                        False                          False   \n",
       "2       None                        False                          False   \n",
       "\n",
       "                                            question  \\\n",
       "0  {'problem': 'How many seconds are in 7.8 minut...   \n",
       "1  {'problem': 'How many positive two-digit integ...   \n",
       "2  {'problem': 'The fifth and eighth terms of a g...   \n",
       "\n",
       "                                               label  \n",
       "0  {'steps': [{'completions': [{'text': '7.8 minu...  \n",
       "1  {'steps': [{'completions': [{'text': \"Let's ca...  \n",
       "2  {'steps': [{'completions': [{'text': 'So we ha...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = []\n",
    "for example in dataset_stream[\"train\"].take(3):\n",
    "    samples.append(example)\n",
    "\n",
    "df_samples = pd.DataFrame(samples)\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples.to_csv('csv/prm800k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Engine\n",
    "engine = get_engine(\"gemini-1.5-pro\")\n",
    "tg.set_backward_engine(\"gemini-1.5-pro\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with TextualVerifierV2\n",
    "def evaluate_with_tv2(row_data):\n",
    "    match = initial_solution[initial_solution[\"id\"] == row_data[\"id\"]]\n",
    "    if match.empty:\n",
    "        return None  # or raise error\n",
    "    formatted_question = match.iloc[0][\"formatted_question\"]\n",
    "    result = {\n",
    "        \"id\": row_data[\"id\"],\n",
    "        \"raw_solution\": row_data[\"raw_solution\"],\n",
    "        \"correct_answer\": row_data[\"correct_answer\"],\n",
    "        \"source\": row_data[\"source\"],\n",
    "        \"subject\": row_data[\"subject\"]\n",
    "    }\n",
    "    \n",
    "    solution = Variable(row_data[\"raw_solution\"],\n",
    "                    requires_grad=True,\n",
    "                    role_description=f\"Solution to the math question: {formatted_question}\")\n",
    "    loss_system_prompt = Variable(\"\"\"You will evaluate a solution to a math question. \n",
    "                                    Do not attempt to solve it yourself, do not give a solution, \n",
    "                                    only identify errors. Be super concise.\"\"\",\n",
    "                                    requires_grad=False,\n",
    "                                    role_description=\"system prompt\")\n",
    "    loss = TextLoss(loss_system_prompt, engine=engine)\n",
    "\n",
    "    # TextualVerifierV2\n",
    "    verifier = TextualVerifierV2Analysis(verifier_engine=engine, step_eval_iterations=3, logger=False)\n",
    "    loss_result = loss(solution)\n",
    "    verified_result = verifier.verify(instance=solution, \n",
    "                                    prompt=loss_system_prompt,\n",
    "                                    calculation=loss_result)\n",
    "\n",
    "    print(verified_result)\n",
    "    result[f\"verified_solution\"] = solution.value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary error lies in inconsistently accounting for carbon atoms contributed by the Grignard reagent. In Step 1, only the phenyl group's carbon is considered, neglecting the carbon directly attached to the magnesium bromide.  This oversight then propagates through subsequent steps.  To improve the process, meticulously account for *all* carbon atoms from *each* reactant involved in forming the products.  Specifically, when considering Grignard reactions, remember that the alkyl/aryl group acts as a nucleophile, contributing its entire carbon framework to the product.  Apply this rigorous atom-tracking approach consistently throughout the synthesis pathway to accurately determine the total carbon count in each product.\n",
      "Completed in 0.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "optimal_workers = min(32, os.cpu_count() * 4)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=optimal_workers) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = [\n",
    "        executor.submit(evaluate_with_tv2, row.to_dict()) \n",
    "        for _, row in initial_solution[:1].iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "\n",
    "raw_textgrad = pd.DataFrame(results)\n",
    "\n",
    "print(f\"Completed in {time.time() - start_time:.1f} seconds\")\n",
    "raw_textgrad.to_csv('results/tv2_textgrad.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "860e0dc2175a55dd9a80ac360791d93c13f4935a3c9aca3a9a76262c7d69eace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
