{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment TextualVerifier Using Best Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textgrad as tg\n",
    "from textgrad.engine import get_engine\n",
    "from textgrad.variable import Variable\n",
    "from textgrad.optimizer import TextualGradientDescent\n",
    "from textgrad.verifier import TextualVerifierExperiment\n",
    "from textgrad.loss import TextLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"dataset/sample/prm800k-03-algo3-clean.csv\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine(\"gemini-1.5-pro\")\n",
    "tg.set_backward_engine(\"gemini-1.5-pro\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_steps(steps):\n",
    "    formatted_steps = \"\"\n",
    "    for step in steps:\n",
    "        new_step = f\"<Step>{step['text']}</Step>\\n\"\n",
    "        formatted_steps += new_step\n",
    "    return formatted_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def evaluate_sample_with_textgrad_textual_verifier(row_data):\n",
    "    problem = row_data['problem'] \n",
    "    steps_list = ast.literal_eval(row_data['steps'])\n",
    "    solution_steps = format_steps(steps_list)\n",
    "    print(problem)\n",
    "    print(solution_steps)\n",
    "\n",
    "    solution = Variable(solution_steps,\n",
    "                        requires_grad=True,\n",
    "                        role_description=f\"Solution to the math question: {problem}\")\n",
    "    verification_prompt = Variable(\"You will evaluate the solution to a math question.\",\n",
    "                                    requires_grad=False,\n",
    "                                    role_description=\"system prompt\")\n",
    "\n",
    "    # TextualVerifierV3\n",
    "    verifier = TextualVerifierExperiment(verifier_engine=engine, step_eval_iterations=3, logger=True)\n",
    "    verified_result = verifier.verify(instance=solution, \n",
    "                                    prompt=verification_prompt,\n",
    "                                    calculation=solution)\n",
    "    verified_result_value = verified_result.value\n",
    "\n",
    "    print(verified_result_value)\n",
    "\n",
    "    # result = {\n",
    "    #     \"id\": row_data[\"id\"],\n",
    "    #     \"raw_solution\": row_data[\"raw_solution\"],\n",
    "    #     \"correct_answer\": row_data[\"correct_answer\"],\n",
    "    #     \"source\": row_data[\"source\"],\n",
    "    #     \"subject\": row_data[\"subject\"]\n",
    "    # }\n",
    "\n",
    "    # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=128) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = [\n",
    "        executor.submit(evaluate_sample_with_textgrad_textual_verifier, row.to_dict()) \n",
    "        for _, row in sample[26:27].iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "\n",
    "# experiment_df = pd.DataFrame(results)\n",
    "\n",
    "# print(f\"Completed in {time.time() - start_time:.1f} seconds\")\n",
    "# experiment_df.to_csv('results/prm800k-03-algo3-clean-result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "860e0dc2175a55dd9a80ac360791d93c13f4935a3c9aca3a9a76262c7d69eace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
