{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA PRM800K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as scp\n",
    "# import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import polyfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm800k_test = pd.read_csv(\"datasets/prm800k-test.csv\")\n",
    "prm800k_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRM800K Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column                          | Data Type       | Description                                                                                                                                                              |\n",
    "| ------------------------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| `labeler`                       | `str` (UUID)    | Unique identifier of the annotator or system that labeled the reasoning steps.                                                                                           |\n",
    "| `timestamp`                     | `datetime`      | Timestamp indicating when the reasoning or labeling was performed. Useful for batch or temporal analysis.                                                                |\n",
    "| `generation`                    | `str` or `null` | (Optional) May contain the ID of the generative model that produced the reasoning steps. Can be `null` for human-generated responses.                                    |\n",
    "| `is_quality_control_question`   | `bool`          | `True` if the question is used for quality control purposes, e.g., testing annotator reliability.                                                                        |\n",
    "| `is_initial_screening_question` | `bool`          | `True` if the question was used for screening labelers before they start actual annotation tasks.                                                                        |\n",
    "| `question`                      | `dict`          | Contains the main question data, typically with keys:<br>• `problem`: the math problem in LaTeX or plain text<br>• `ground_truth_answer`: the correct answer as a string |\n",
    "| `label`                         | `dict`          | Holds reasoning steps and associated labels. This includes a list of reasoning `steps`, each with several completions and possibly human feedback.                       |\n",
    "\n",
    "The label['steps'] field contains a list of reasoning steps. Each step follows this structure:\n",
    "```\n",
    "{\n",
    "  \"completions\": [\n",
    "    {\n",
    "      \"text\": \"Some reasoning text...\",\n",
    "      \"rating\": 1,\n",
    "      \"flagged\": false\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"human_completion\": {\n",
    "    \"text\": \"Manual correction or insight\",\n",
    "    \"source\": \"human\",\n",
    "    \"corrected_rating\": null,\n",
    "    \"flagged\": false\n",
    "  },\n",
    "  \"chosen_completion\": 2\n",
    "}\n",
    "```\n",
    "Fields Explained\n",
    "- completions: Multiple reasoning candidates for a given step.\n",
    "- text: The reasoning text generated by a model or human.\n",
    "- rating: Quality label of the reasoning:\n",
    "```\n",
    "1: correct\n",
    "0: redundant\n",
    "-1: incorrect\n",
    "```\n",
    "- flagged: Boolean indicating problematic or inappropriate completions.\n",
    "- chosen_completion: Index of the preferred or accepted completion for the step.\n",
    "- human_completion (optional): Manual input by a human evaluator to correct or guide the reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for PRM800K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the lack of visibility caused by the deeply nested JSON format in the label column, especially the steps field. I have added several new columns to make exploration and analysis of PRM800K easier.\n",
    "\n",
    "| **Column**                         | **Description**                                                                                                                                     |\n",
    "|-----------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **`total_steps`**                 | Total number of reasoning steps per question.                                                                                                       |\n",
    "| **`total_steps_have_neg_1`**      | Total number of steps that include at least one completion rated **-1** (indicating incorrect or misleading reasoning).                           |\n",
    "| **`steps_neg_1`**                 | List of step indices (e.g., `[1, 2, 3, 4]`) where at least one completion has a rating of **-1**.                                                  |\n",
    "| **`total_neg_1_sequence_from_last_step`** | Number of consecutive steps (counting backward from the last step) that contain at least one **-1** rating. Useful for analyzing late degradation. |\n",
    "| **`total_steps_have_zero`**       | Total number of steps that include at least one completion rated **0** (neutral or uninformative reasoning).                                       |\n",
    "| **`steps_zero`**                  | List of step indices where at least one completion has a rating of **0**.                                                                          |\n",
    "| **`total_steps_have_pos_1_or_human`**      | Total number of steps that include at least one completion rated **1** (good or helpful reasoning) or human completion.                                                |\n",
    "| **`steps_pos_1_or_human`**                 | List of step indices where at least one completion has a rating of **1** or human completion.                                                                          |\n",
    "| **`total_steps_have_combination`**| Total number of steps that contain **all three types of ratings**: **-1**, **0**, and **1/human**. Helps identify steps with diverse or conflicting judgment. |\n",
    "| **`finish_reason`**               | Original `finish_reason` field from the dataset, indicating how the reasoning process was concluded (e.g., `\"solution\"`, `\"give_up\"`).             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to Dict (Convert JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def string_to_dict(input_string):\n",
    "    input_string = input_string.strip()\n",
    "\n",
    "    try:\n",
    "        json_string = input_string.replace(\"'\", '\"')\n",
    "        json_string = json_string.replace('True', 'true').replace('False', 'false').replace('None', 'null')\n",
    "        return json.loads(json_string)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return ast.literal_eval(input_string)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if input_string.strip().startswith('{') and input_string.strip().endswith('}'):\n",
    "            return eval(input_string)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(f\"Cannot parse string as dictionary: {input_string[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Rating Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step_info(step):    \n",
    "    neg_1 = 0\n",
    "    zero = 0\n",
    "    pos_1 = 0\n",
    "    \n",
    "    for idx, completion in enumerate(step['completions']):\n",
    "        rating = completion['rating']\n",
    "        if rating == -1:\n",
    "            neg_1 += 1\n",
    "        elif rating == 0:\n",
    "            zero += 1\n",
    "        elif rating == 1:\n",
    "            pos_1 += 1\n",
    "\n",
    "    human_completion = step['human_completion']\n",
    "\n",
    "    rating_info = {\n",
    "        \"-1\": neg_1,\n",
    "        \"0\": zero,\n",
    "        \"1\": pos_1,\n",
    "        \"human_completion\": human_completion        \n",
    "    }\n",
    "    \n",
    "    return rating_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "\"\"\"\n",
    "[\n",
    "  {\"-1\": 1, \"0\": 1, \"1\": 1, \"human_completion\": null},\n",
    "  {\"-1\": 1, \"0\": 1, \"1\": 1, \"human_completion\": null},\n",
    "  {\"-1\": 1, \"0\": 0, \"1\": 0, \"human_completion\": {\n",
    "      \"text\": \"No, it shouldn't. The leading term of the product is the product of the leading terms of the factors, and the degree is the sum of the degrees.\",\n",
    "      \"rating\": null,\n",
    "      \"source\": \"human\",\n",
    "      \"flagged\": false,\n",
    "      \"corrected_rating\": null\n",
    "  }},\n",
    "  {\"-1\": 0, \"0\": 0, \"1\": 1, \"human_completion\": null},\n",
    "  {\"-1\": 1, \"0\": 0, \"1\": 1, \"human_completion\": null},\n",
    "  {\"-1\": 0, \"0\": 0, \"1\": 1, \"human_completion\": null},\n",
    "  {\"-1\": 1, \"0\": 1, \"1\": 1, \"human_completion\": null}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def rating_breakdown(rating_infos):\n",
    "    steps_neg_1 = []\n",
    "    total_neg_1_sequence_from_last_step = 0\n",
    "    steps_zero = []\n",
    "    steps_pos_1_or_human = []\n",
    "    total_steps_have_combination = 0\n",
    "    \n",
    "    counter = 1\n",
    "    for step in rating_infos:\n",
    "        is_neg_1 = step[\"-1\"] > 0\n",
    "        is_zero = step[\"0\"] > 0\n",
    "        is_pos_1 = step[\"1\"] > 0 or step[\"human_completion\"] is not None\n",
    "\n",
    "        if is_neg_1:\n",
    "            steps_neg_1.append(counter)\n",
    "        if is_zero:\n",
    "            steps_zero.append(counter)\n",
    "        if is_pos_1:\n",
    "            steps_pos_1_or_human.append(counter)\n",
    "        if is_neg_1 and is_zero and is_pos_1:\n",
    "            total_steps_have_combination += 1\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    reversed_steps_neg_1 = steps_neg_1[::-1]\n",
    "    if reversed_steps_neg_1 and reversed_steps_neg_1[0] == len(rating_infos):\n",
    "        pivot = len(rating_infos)\n",
    "        for step in reversed_steps_neg_1:\n",
    "            if step == pivot:\n",
    "                total_neg_1_sequence_from_last_step += 1\n",
    "            else:\n",
    "                break\n",
    "            pivot -= 1\n",
    "            \n",
    "    result = {\n",
    "        \"total_steps_have_neg_1\": len(steps_neg_1),\n",
    "        \"steps_neg_1\": steps_neg_1,\n",
    "        \"total_neg_1_sequence_from_last_step\": total_neg_1_sequence_from_last_step,\n",
    "        \"total_steps_have_zero\": len(steps_zero),\n",
    "        \"steps_zero\": steps_zero,\n",
    "        \"total_steps_have_pos_1_or_human\": len(steps_pos_1_or_human),\n",
    "        \"steps_pos_1_or_human\": steps_pos_1_or_human,\n",
    "        \"total_steps_have_combination\": total_steps_have_combination\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process PRM800K Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(prm800k_train):\n",
    "    results = []\n",
    "    \n",
    "    for index, row in prm800k_train.iterrows():\n",
    "        try:\n",
    "            data = string_to_dict(row['label'])\n",
    "            finish_reason = data['finish_reason']\n",
    "            rating_infos = []\n",
    "            \n",
    "            # Process each step\n",
    "            for step_no, step in enumerate(data['steps']):\n",
    "                rating_info = get_step_info(step)\n",
    "                rating_infos.append(rating_info)\n",
    "\n",
    "            result = rating_breakdown(rating_infos)\n",
    "            new_result = {\n",
    "                **row.to_dict(),\n",
    "                \"total_steps\": len(rating_infos),\n",
    "                **result,\n",
    "                \"finish_reason\": finish_reason,\n",
    "            }\n",
    "            results.append(new_result)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_engineered = feature_engineering(prm800k_test)\n",
    "df_feature_engineered = df_feature_engineered.sort_values('total_steps_have_combination', ascending=False)\n",
    "df_feature_engineered.to_csv('datasets/prm800k-test-feature-engineered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_engineered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Total Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_steps_sum(df):\n",
    "    return df['total_steps'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Finish Reason Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finish_reason_counts(df):\n",
    "    return df['finish_reason'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filter Only \"solution\" Rows (Get Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_solution_finish_reason(df):\n",
    "    return df[df['finish_reason'] == 'solution']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter Rows Where Positive Exist on All Steps (Get Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all_steps_exist_pos_or_human(df):\n",
    "    return df[df['total_steps'] == df['total_steps_have_pos_1_or_human']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Total Steps Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_total_steps_distribution(df):\n",
    "    dist = df['total_steps'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(dist.index, dist.values, color=\"#4C72B0\", edgecolor=\"black\")\n",
    "    \n",
    "    plt.title(\"Distribution of total_steps\", fontsize=14)\n",
    "    plt.xlabel(\"Total Steps\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Rows\", fontsize=12)\n",
    "    plt.xticks(dist.index)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Negative Steps Position Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "def plot_negative_steps_tertile_distribution(df):\n",
    "    tertile_counter = Counter({\"T1\": 0, \"T2\": 0, \"T3\": 0})\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            steps = row['steps_neg_1']\n",
    "            total_steps = row['total_steps']\n",
    "\n",
    "            if isinstance(steps, str):\n",
    "                steps = ast.literal_eval(steps)\n",
    "            if not isinstance(steps, list) or total_steps == 0:\n",
    "                continue\n",
    "\n",
    "            for step in steps:\n",
    "                percent_pos = (step / total_steps) * 100\n",
    "                if percent_pos <= 33:\n",
    "                    tertile_counter[\"T1\"] += 1\n",
    "                elif percent_pos <= 66:\n",
    "                    tertile_counter[\"T2\"] += 1\n",
    "                else:\n",
    "                    tertile_counter[\"T3\"] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    tertile_labels = [\"T1 (0–33%)\", \"T2 (34–66%)\", \"T3 (67–100%)\"]\n",
    "    counts = [tertile_counter[\"T1\"], tertile_counter[\"T2\"], tertile_counter[\"T3\"]]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(tertile_labels, counts, color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"], edgecolor=\"black\")\n",
    "    plt.title(\"Tertile Distribution of Negative (-1) Steps\", fontsize=14)\n",
    "    plt.xlabel(\"Tertile Step Position\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Times Marked -1\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Zero Steps Position Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "def plot_zero_steps_tertile_distribution(df):\n",
    "    tertile_counter = Counter({\"T1\": 0, \"T2\": 0, \"T3\": 0})\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            steps = row['steps_zero']\n",
    "            total_steps = row['total_steps']\n",
    "\n",
    "            if isinstance(steps, str):\n",
    "                steps = ast.literal_eval(steps)\n",
    "            if not isinstance(steps, list) or total_steps == 0:\n",
    "                continue\n",
    "\n",
    "            for step in steps:\n",
    "                percent_pos = (step / total_steps) * 100\n",
    "                if percent_pos <= 33:\n",
    "                    tertile_counter[\"T1\"] += 1\n",
    "                elif percent_pos <= 66:\n",
    "                    tertile_counter[\"T2\"] += 1\n",
    "                else:\n",
    "                    tertile_counter[\"T3\"] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    tertile_labels = [\"T1 (0–33%)\", \"T2 (34–66%)\", \"T3 (67–100%)\"]\n",
    "    counts = [tertile_counter[\"T1\"], tertile_counter[\"T2\"], tertile_counter[\"T3\"]]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(tertile_labels, counts, color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"], edgecolor=\"black\")\n",
    "    plt.title(\"Tertile Distribution of Zero (0) Steps\", fontsize=14)\n",
    "    plt.xlabel(\"Tertile Step Position\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Times Marked 0\", fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA PRM800K Test Feature Engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prm800k_test_feature_engineered = prm800k_train = pd.read_csv(\"datasets/prm800k-test-feature-engineered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Total Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_steps_sum(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Finish Reason Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_finish_reason_counts(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filter Only \"solution\" Rows (Get Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prm800k_test_feature_engineered = filter_solution_finish_reason(df_prm800k_test_feature_engineered)\n",
    "df_prm800k_test_feature_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_steps_sum(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter Rows Where Positive Exist on All Steps (Get Valid Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prm800k_test_feature_engineered = filter_all_steps_exist_pos_or_human(df_prm800k_test_feature_engineered)\n",
    "df_prm800k_test_feature_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_steps_sum(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Total Steps Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_total_steps_distribution(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Negative Steps Position Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_negative_steps_tertile_distribution(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Zero Steps Position Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_zero_steps_tertile_distribution(df_prm800k_test_feature_engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Valid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prm800k_test_feature_engineered.to_csv('datasets/prm800k-test-valid-data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit ('3.11.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b649c18c59123e9cb819750d1a320031f2b93bee7a3106a6e5d9c7574eec0da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
