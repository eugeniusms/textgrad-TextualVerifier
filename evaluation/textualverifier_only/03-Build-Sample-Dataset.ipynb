{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm800k = pd.read_csv(\"datasets/prm800k-test-valid-data.csv\")\n",
    "prm800k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "def string_to_dict(input_string):\n",
    "    input_string = input_string.strip()\n",
    "\n",
    "    try:\n",
    "        json_string = input_string.replace(\"'\", '\"')\n",
    "        json_string = json_string.replace('True', 'true').replace('False', 'false').replace('None', 'null')\n",
    "        return json.loads(json_string)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return ast.literal_eval(input_string)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if input_string.strip().startswith('{') and input_string.strip().endswith('}'):\n",
    "            return eval(input_string)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(f\"Cannot parse string as dictionary: {input_string[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_steps(steps):\n",
    "    ground_truth_steps = []\n",
    "    steps_list = ast.literal_eval(steps) if isinstance(steps, str) else steps\n",
    "    for step in steps_list:\n",
    "        if step['human_completion'] != None:\n",
    "            ground_truth_steps.append(step['human_completion']['text'])\n",
    "        else:\n",
    "            for completion in step['completions']: \n",
    "                if completion['rating'] == 1:\n",
    "                    ground_truth_steps.append(completion['text']) \n",
    "                    break  # Break after finding first rating=1 completion\n",
    "    return ground_truth_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, function):\n",
    "    results = []\n",
    "    counter = 1\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            question = string_to_dict(row['question'])\n",
    "            data = string_to_dict(row['label'])\n",
    "            steps = data['steps']\n",
    "            new_columns = function(steps)\n",
    "\n",
    "            new_result = {\n",
    "                \"id\": counter,\n",
    "                \"labeler\": row[\"labeler\"],\n",
    "                \"timestamp\": row[\"timestamp\"],\n",
    "                \"problem\": question[\"problem\"],\n",
    "                \"ground_truth_answer\": question[\"ground_truth_answer\"],\n",
    "                \"total_steps\": row[\"total_steps\"],\n",
    "                \"ground_truth_steps\": get_ground_truth_steps(steps),\n",
    "                **new_columns,\n",
    "            }\n",
    "            results.append(new_result)\n",
    "            counter += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps_info(steps):\n",
    "    neg_1 = 0\n",
    "    zero = 0\n",
    "    pos_1 = 0\n",
    "\n",
    "    for step in steps:\n",
    "        match step[\"rating\"]:\n",
    "            case -1:\n",
    "                neg_1 += 1\n",
    "            case 0:\n",
    "                zero += 1\n",
    "            case 1:\n",
    "                pos_1 += 1\n",
    "    \n",
    "    steps_info = {\n",
    "        \"neg_1\": neg_1,\n",
    "        \"zero\": zero,\n",
    "        \"pos_1\": pos_1\n",
    "    }\n",
    "\n",
    "    return steps_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_steps_sum_each_rating(df):\n",
    "    result = {\n",
    "        \"total_neg_1\": df['neg_1'].sum(),\n",
    "        \"total_zero\": df['zero'].sum(),\n",
    "        \"total_pos_1\": df['pos_1'].sum()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_where_pos1_equals_total_steps(df):\n",
    "    return df[df[\"pos_1\"] != df[\"total_steps\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ALGO 1] Merge Completions in Each Steps to Index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_completions_to_idx_0(steps):\n",
    "    new_steps = []\n",
    "\n",
    "    # ALGO: get first completion in every steps\n",
    "    for step_no, step in enumerate(steps):\n",
    "        collect_step = step['completions'][0]\n",
    "        new_steps.append(collect_step)\n",
    "\n",
    "    steps_info = get_steps_info(new_steps)\n",
    "    result = {\n",
    "        \"steps\": new_steps,\n",
    "        **steps_info\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_1 = process_data(prm800k, merge_completions_to_idx_0)\n",
    "df_option_1.to_csv(\"datasets/sample/prm800k-01-first-completion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Total neg_1, zero, pos_1\n",
    "get_total_steps_sum_each_rating(df_option_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Still Not Good, Total Pos 1 Too Much, Many of Datas Only Pos 1 No Neg 1 & Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ALGO 2] Real Condition - For Early Step (<30%) Use 1, Then After It Random, If Found -1 The Use -1/0 After It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def algo_2(steps):\n",
    "    new_steps = []\n",
    "    t1 = len(steps) / 3\n",
    "\n",
    "    # ALGO: get first completion in every steps\n",
    "    counter = 1\n",
    "    latest_step = 1\n",
    "    for step_no, step in enumerate(steps):\n",
    "        collect_step = step['completions'][0]\n",
    "        rating = collect_step[\"rating\"]\n",
    "\n",
    "        if counter <= t1:\n",
    "            # CASE <= 33%\n",
    "            if rating != 1:\n",
    "                flag = False\n",
    "                for idx, completion in enumerate(step['completions']):\n",
    "                    if completion[\"rating\"] == 1:\n",
    "                        collect_step = completion\n",
    "                        flag = True\n",
    "                        break\n",
    "                if not flag:\n",
    "                    collect_step = step[\"human_completion\"]\n",
    "                    collect_step[\"rating\"] = 1\n",
    "            new_steps.append(collect_step)\n",
    "            counter += 1\n",
    "            continue\n",
    "        \n",
    "        # After 33%\n",
    "        if latest_step == -1:\n",
    "            for idx, completion in enumerate(step['completions']):\n",
    "                if completion[\"rating\"] == -1:\n",
    "                    collect_step = completion\n",
    "                    break\n",
    "        \n",
    "            # Berusaha -1, kalau ngga ketemu pakai default (first completion)\n",
    "            new_steps.append(collect_step)\n",
    "            continue\n",
    "        \n",
    "        total_completions = len(step['completions'])\n",
    "        random_completion = step['completions'][random.randint(0, total_completions-1)]\n",
    "        new_steps.append(random_completion)\n",
    "        latest_step = random_completion['rating']\n",
    "\n",
    "    steps_info = get_steps_info(new_steps)\n",
    "    result = {\n",
    "        \"steps\": new_steps,\n",
    "        **steps_info\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_2 = process_data(prm800k, algo_2)\n",
    "df_option_2.to_csv(\"datasets/sample/prm800k-02-algo2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Total neg_1, zero, pos_1\n",
    "get_total_steps_sum_each_rating(df_option_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Still Not Good, Total Pos 1 Too Much, Many of Datas Only Pos 1 No Neg 1 & Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try To Drop All Pos 1\n",
    "clean_df_option_2 = drop_rows_where_pos1_equals_total_steps(df_option_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_option_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_steps_sum_each_rating(clean_df_option_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Good, Natural PRM800K\n",
    "| Label | Jumlah | Persentase |\n",
    "| ----- | ------ | ---------- |\n",
    "| -1    | 211    | \\~17.3%    |\n",
    "| 0     | 54     | \\~4.4%     |\n",
    "| +1    | 955    | \\~78.3%    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_option_2.to_csv(\"datasets/sample/prm800k-02-algo2-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ALGO 3] Real Condition - Random Rating From Early, If Found -1 The Use -1/0 After It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def algo_3(steps):\n",
    "    new_steps = []\n",
    "\n",
    "    latest_step = 1\n",
    "    for step_no, step in enumerate(steps):\n",
    "        collect_step = step['completions'][0]\n",
    "\n",
    "        # From Early\n",
    "        if latest_step == -1:\n",
    "            for idx, completion in enumerate(step['completions']):\n",
    "                if completion[\"rating\"] == -1:\n",
    "                    collect_step = completion\n",
    "                    break\n",
    "        \n",
    "            # Berusaha -1, kalau ngga ketemu pakai default (first completion)\n",
    "            new_steps.append(collect_step)\n",
    "            continue\n",
    "        \n",
    "        total_completions = len(step['completions'])\n",
    "        random_completion = step['completions'][random.randint(0, total_completions-1)]\n",
    "        new_steps.append(random_completion)\n",
    "        latest_step = random_completion['rating']\n",
    "\n",
    "    steps_info = get_steps_info(new_steps)\n",
    "    result = {\n",
    "        \"steps\": new_steps,\n",
    "        **steps_info\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_3 = process_data(prm800k, algo_3)\n",
    "df_option_3.to_csv(\"datasets/sample/prm800k-02-algo3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try To Drop All Pos 1\n",
    "clean_df_option_3 = drop_rows_where_pos1_equals_total_steps(df_option_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_option_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_steps_sum_each_rating(clean_df_option_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_option_3.to_csv(\"datasets/sample/prm800k-03-algo3-clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit ('3.11.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b649c18c59123e9cb819750d1a320031f2b93bee7a3106a6e5d9c7574eec0da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
